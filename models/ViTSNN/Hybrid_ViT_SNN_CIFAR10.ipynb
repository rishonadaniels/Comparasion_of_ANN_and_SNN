{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63593785-cd24-4cea-aea9-53bb073a7e30",
      "metadata": {
        "id": "63593785-cd24-4cea-aea9-53bb073a7e30"
      },
      "outputs": [],
      "source": [
        "pip install snntorch timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca389a50-82a0-477d-b92b-82263e60077c",
      "metadata": {
        "id": "ca389a50-82a0-477d-b92b-82263e60077c",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import snntorch as snn\n",
        "import timm\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Hyperparameters\n",
        "# -----------------------------\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 8\n",
        "learning_rate = 0.0001  # Lower LR for fine-tuning\n",
        "weight_decay = 1e-4  # Regularization\n",
        "momentum = 0.9  # For SGD (if used instead of Adam)\n",
        "\n",
        "# -----------------------------\n",
        "# Load CIFAR-10 Dataset\n",
        "# -----------------------------\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),  # Resize to 224x224 (ViT input size)\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.CIFAR10),  # Stronger augmentation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),  # Resize test images to 224x224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Load Pretrained ViT Model\n",
        "# -----------------------------\n",
        "#model = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)\n",
        "model = timm.create_model('vit_tiny_patch16_224', pretrained=True, num_classes=10)\n",
        "print(model)\n",
        "\n",
        "# Custom wrapper to return only spikes (not membrane potential)\n",
        "class SpikingLeaky(nn.Module):\n",
        "    def __init__(self, beta=0.9):\n",
        "        super().__init__()\n",
        "        self.leaky = snn.Leaky(beta=beta)\n",
        "\n",
        "    def forward(self, x):\n",
        "        spike, _ = self.leaky(x)  # Extract only the spike output\n",
        "        return spike  # Drop the membrane potential\n",
        "\n",
        "# Function to replace activations with SpikingLeaky\n",
        "def replace_activations(module):\n",
        "    for name, child in module.named_children():\n",
        "        if isinstance(child, (nn.ReLU, nn.GELU)):  # Check if it's ReLU or GELU\n",
        "            setattr(module, name, SpikingLeaky(beta=0.9))  # Replace with custom wrapper\n",
        "        else:\n",
        "            replace_activations(child)  # Recursively apply to submodules\n",
        "\n",
        "def reset_states(model):\n",
        "    for module in model.modules():\n",
        "        if hasattr(module, \"reset\") and callable(module.reset):\n",
        "            module.reset()\n",
        "\n",
        "def detach_hidden_states(model):\n",
        "    for module in model.modules():\n",
        "        # Check for an attribute commonly used to store the hidden state\n",
        "        # Adjust 'mem' to match the actual attribute name used in your spiking neuron modules.\n",
        "        if hasattr(module, 'mem') and module.mem is not None:\n",
        "            module.mem = module.mem.detach()\n",
        "# Apply the function to modify the model\n",
        "replace_activations(model)\n",
        "\n",
        "# Print the modified model to verify changes\n",
        "print(model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4693d95a-f140-449e-87f2-5c1b5a36c6cc",
      "metadata": {
        "id": "4693d95a-f140-449e-87f2-5c1b5a36c6cc"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.head = nn.Linear(model.head.in_features, 10)  # Modify last layer for CIFAR-10\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss Function & Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "# -----------------------------\n",
        "#Fine-Tuning Function\n",
        "# -----------------------------\n",
        "training_accuracies = []\n",
        "\n",
        "# Number of simulation time steps per sample presentation\n",
        "num_steps = 25\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Reset or detach the hidden state at the start of each batch if necessary\n",
        "            # (if you need a complete reset, you might have a custom reset function too)\n",
        "            detach_hidden_states(model)\n",
        "\n",
        "            out_sum = 0.0\n",
        "            for t in range(num_steps):\n",
        "                out = model(images)\n",
        "                # For all but the final time step, detach the output to prevent backpropagation through time.\n",
        "                if t < num_steps - 1:\n",
        "                    out_sum += out.detach()\n",
        "                else:\n",
        "                    out_sum += out  # Keep the final output's graph intact.\n",
        "            outputs = out_sum / num_steps\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Compute training accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        training_accuracy = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Training Accuracy: {training_accuracy:.2f}%\")\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            out_sum = 0.0\n",
        "            for t in range(num_steps):\n",
        "                out = model(images)\n",
        "                out_sum += out\n",
        "\n",
        "            outputs = out_sum / num_steps\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy on the test set: {accuracy:.2f}%')\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Main Loop (Train & Test)\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    train()\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time:.2f} seconds\")\n",
        "\n",
        "    # Measure inference time\n",
        "    start_time = time.time()\n",
        "    test()\n",
        "    end_time = time.time()\n",
        "    inference_time = end_time - start_time\n",
        "    print(f\"Inference time: {inference_time:.2f} seconds for the entire test set\")\n",
        "\n",
        "    # Calculate per-sample inference time\n",
        "    per_sample_inference_time = inference_time / len(test_dataset)\n",
        "    print(f\"Inference time per sample: {per_sample_inference_time:.6f} seconds\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}