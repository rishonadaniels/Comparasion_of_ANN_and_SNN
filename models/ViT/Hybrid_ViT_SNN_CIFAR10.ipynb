{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63593785-cd24-4cea-aea9-53bb073a7e30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63593785-cd24-4cea-aea9-53bb073a7e30",
    "outputId": "8c72f0b5-4f1b-4c81-dc4c-50c2b97b29a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snntorch in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (0.9.1)\n",
      "Requirement already satisfied: torch>=1.1.0 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from snntorch) (2.3.0)\n",
      "Requirement already satisfied: pandas in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from snntorch) (2.0.3)\n",
      "Requirement already satisfied: matplotlib in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from snntorch) (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from snntorch) (1.24.3)\n",
      "Requirement already satisfied: nir in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from snntorch) (1.0.1)\n",
      "Requirement already satisfied: nirtorch in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from snntorch) (1.0)\n",
      "Requirement already satisfied: filelock in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from torch>=1.1.0->snntorch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from torch>=1.1.0->snntorch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from torch>=1.1.0->snntorch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from torch>=1.1.0->snntorch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from torch>=1.1.0->snntorch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from torch>=1.1.0->snntorch) (2025.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from matplotlib->snntorch) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from matplotlib->snntorch) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from matplotlib->snntorch) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from matplotlib->snntorch) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from matplotlib->snntorch) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from matplotlib->snntorch) (10.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from matplotlib->snntorch) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from matplotlib->snntorch) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from matplotlib->snntorch) (6.4.0)\n",
      "Requirement already satisfied: h5py in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from nir->snntorch) (3.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from pandas->snntorch) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from pandas->snntorch) (2023.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->snntorch) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->snntorch) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from jinja2->torch>=1.1.0->snntorch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from sympy->torch>=1.1.0->snntorch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install snntorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dec7bc7-3b57-4c70-bc95-37a4141c1c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (1.0.14)\n",
      "Requirement already satisfied: torch in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from timm) (2.3.0)\n",
      "Requirement already satisfied: torchvision in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from timm) (0.18.0)\n",
      "Requirement already satisfied: pyyaml in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from timm) (0.28.1)\n",
      "Requirement already satisfied: safetensors in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from timm) (0.5.2)\n",
      "Requirement already satisfied: filelock in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from huggingface_hub->timm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from huggingface_hub->timm) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from huggingface_hub->timm) (24.1)\n",
      "Requirement already satisfied: requests in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from huggingface_hub->timm) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from huggingface_hub->timm) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from torch->timm) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from torch->timm) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from torch->timm) (3.1.4)\n",
      "Requirement already satisfied: numpy in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from torchvision->timm) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from torchvision->timm) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from jinja2->torch->timm) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from requests->huggingface_hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages (from sympy->torch->timm) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca389a50-82a0-477d-b92b-82263e60077c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ee0506db76c04fc59233c0e570ab0aab",
      "87d794c28ff747ad8a9b4e9d8c2ab341",
      "83eab347f17247b184c4a26f25c36a17",
      "56dc90a26448400e94cd219f8d28d732",
      "b9c51bf377ab41489df80de55ec2a0a2",
      "bf5e0726452c4832a4a78c2534e7aa4d",
      "cc7be5b519694128bd35605957f9a420",
      "32c286a4e83f44b3ad67b2a6b7e18c0c",
      "79b667e7997046c886222494ec4f05f1",
      "e9659a96732742d9a5838e6847071497",
      "61633da9820e43deb40bd4598af54c40"
     ]
    },
    "id": "ca389a50-82a0-477d-b92b-82263e60077c",
    "outputId": "f4e73a97-1d5a-4e62-a8a9-4137b607fd19",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishonad/anaconda3/envs/deep_learn/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (patch_drop): Identity()\n",
      "  (norm_pre): Identity()\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "  (fc_norm): Identity()\n",
      "  (head_drop): Dropout(p=0.0, inplace=False)\n",
      "  (head): Linear(in_features=192, out_features=10, bias=True)\n",
      ")\n",
      "VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (patch_drop): Identity()\n",
      "  (norm_pre): Identity()\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): SpikingLeaky(\n",
      "          (leaky): Leaky()\n",
      "        )\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): SpikingLeaky(\n",
      "          (leaky): Leaky()\n",
      "        )\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): SpikingLeaky(\n",
      "          (leaky): Leaky()\n",
      "        )\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): SpikingLeaky(\n",
      "          (leaky): Leaky()\n",
      "        )\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): SpikingLeaky(\n",
      "          (leaky): Leaky()\n",
      "        )\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): SpikingLeaky(\n",
      "          (leaky): Leaky()\n",
      "        )\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): SpikingLeaky(\n",
      "          (leaky): Leaky()\n",
      "        )\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): SpikingLeaky(\n",
      "          (leaky): Leaky()\n",
      "        )\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): SpikingLeaky(\n",
      "          (leaky): Leaky()\n",
      "        )\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): SpikingLeaky(\n",
      "          (leaky): Leaky()\n",
      "        )\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): SpikingLeaky(\n",
      "          (leaky): Leaky()\n",
      "        )\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): SpikingLeaky(\n",
      "          (leaky): Leaky()\n",
      "        )\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "  (fc_norm): Identity()\n",
      "  (head_drop): Dropout(p=0.0, inplace=False)\n",
      "  (head): Linear(in_features=192, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import snntorch as snn\n",
    "import timm\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Hyperparameters\n",
    "# -----------------------------\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 8\n",
    "learning_rate = 0.0001  # Lower LR for fine-tuning\n",
    "weight_decay = 1e-4  # Regularization\n",
    "momentum = 0.9  # For SGD (if used instead of Adam)\n",
    "\n",
    "# -----------------------------\n",
    "# Load CIFAR-10 Dataset\n",
    "# -----------------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),  # Resize to 224x224 (ViT input size)\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.CIFAR10),  # Stronger augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # Resize test images to 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load Pretrained ViT Model\n",
    "# -----------------------------\n",
    "#model = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "model = timm.create_model('vit_tiny_patch16_224', pretrained=True, num_classes=10)\n",
    "print(model)\n",
    "\n",
    "# Custom wrapper to return only spikes (not membrane potential)\n",
    "class SpikingLeaky(nn.Module):\n",
    "    def __init__(self, beta=0.9):\n",
    "        super().__init__()\n",
    "        self.leaky = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "        spike, _ = self.leaky(x)  # Extract only the spike output\n",
    "        return spike  # Drop the membrane potential\n",
    "\n",
    "# Function to replace activations with SpikingLeaky\n",
    "def replace_activations(module):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, (nn.ReLU, nn.GELU)):  # Check if it's ReLU or GELU\n",
    "            setattr(module, name, SpikingLeaky(beta=0.9))  # Replace with custom wrapper\n",
    "        else:\n",
    "            replace_activations(child)  # Recursively apply to submodules\n",
    "\n",
    "def reset_states(model):\n",
    "    for module in model.modules():\n",
    "        if hasattr(module, \"reset\") and callable(module.reset):\n",
    "            module.reset()\n",
    "\n",
    "def detach_hidden_states(model):\n",
    "    for module in model.modules():\n",
    "        # Check for an attribute commonly used to store the hidden state\n",
    "        # Adjust 'mem' to match the actual attribute name used in your spiking neuron modules.\n",
    "        if hasattr(module, 'mem') and module.mem is not None:\n",
    "            module.mem = module.mem.detach()\n",
    "# Apply the function to modify the model\n",
    "replace_activations(model)\n",
    "\n",
    "# Print the modified model to verify changes\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4693d95a-f140-449e-87f2-5c1b5a36c6cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4693d95a-f140-449e-87f2-5c1b5a36c6cc",
    "outputId": "1088499e-0dc8-4ccf-ff49-2e7c729f2398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0000, Training Accuracy: 36.05%\n",
      "Epoch [2/5], Loss: 0.0000, Training Accuracy: 49.52%\n",
      "Epoch [3/5], Loss: 0.0000, Training Accuracy: 52.66%\n",
      "Epoch [4/5], Loss: 0.0000, Training Accuracy: 52.28%\n",
      "Epoch [5/5], Loss: 0.0000, Training Accuracy: 54.50%\n",
      "Training time: 12267.26 seconds\n",
      "Accuracy on the test set: 73.38%\n",
      "Inference time: 197.30 seconds for the entire test set\n",
      "Inference time per sample: 0.019730 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.head = nn.Linear(model.head.in_features, 10)  # Modify last layer for CIFAR-10\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss Function & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# -----------------------------\n",
    "#Fine-Tuning Function\n",
    "# -----------------------------\n",
    "training_accuracies = []\n",
    "\n",
    "# Number of simulation time steps per sample presentation\n",
    "num_steps = 25\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Reset or detach the hidden state at the start of each batch if necessary\n",
    "            # (if you need a complete reset, you might have a custom reset function too)\n",
    "            detach_hidden_states(model)\n",
    "\n",
    "            out_sum = 0.0\n",
    "            for t in range(num_steps):\n",
    "                out = model(images)\n",
    "                # For all but the final time step, detach the output to prevent backpropagation through time.\n",
    "                if t < num_steps - 1:\n",
    "                    out_sum += out.detach()\n",
    "                else:\n",
    "                    out_sum += out  # Keep the final output's graph intact.\n",
    "            outputs = out_sum / num_steps\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Compute training accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        training_accuracy = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Training Accuracy: {training_accuracy:.2f}%\")\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            out_sum = 0.0\n",
    "            for t in range(num_steps):\n",
    "                out = model(images)\n",
    "                out_sum += out\n",
    "\n",
    "            outputs = out_sum / num_steps\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy on the test set: {accuracy:.2f}%')\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main Loop (Train & Test)\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Measure training time\n",
    "    start_time = time.time()\n",
    "    train()\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "    # Measure inference time\n",
    "    start_time = time.time()\n",
    "    test()\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    print(f\"Inference time: {inference_time:.2f} seconds for the entire test set\")\n",
    "\n",
    "    # Calculate per-sample inference time\n",
    "    per_sample_inference_time = inference_time / len(test_dataset)\n",
    "    print(f\"Inference time per sample: {per_sample_inference_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2931bede-7ee8-4a57-a0e1-ae5c066e11f4",
   "metadata": {
    "id": "2931bede-7ee8-4a57-a0e1-ae5c066e11f4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "32c286a4e83f44b3ad67b2a6b7e18c0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56dc90a26448400e94cd219f8d28d732": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9659a96732742d9a5838e6847071497",
      "placeholder": "​",
      "style": "IPY_MODEL_61633da9820e43deb40bd4598af54c40",
      "value": " 22.9M/22.9M [00:00&lt;00:00, 72.2MB/s]"
     }
    },
    "61633da9820e43deb40bd4598af54c40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79b667e7997046c886222494ec4f05f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "83eab347f17247b184c4a26f25c36a17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32c286a4e83f44b3ad67b2a6b7e18c0c",
      "max": 22883348,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_79b667e7997046c886222494ec4f05f1",
      "value": 22883348
     }
    },
    "87d794c28ff747ad8a9b4e9d8c2ab341": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf5e0726452c4832a4a78c2534e7aa4d",
      "placeholder": "​",
      "style": "IPY_MODEL_cc7be5b519694128bd35605957f9a420",
      "value": "model.safetensors: 100%"
     }
    },
    "b9c51bf377ab41489df80de55ec2a0a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf5e0726452c4832a4a78c2534e7aa4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc7be5b519694128bd35605957f9a420": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9659a96732742d9a5838e6847071497": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee0506db76c04fc59233c0e570ab0aab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_87d794c28ff747ad8a9b4e9d8c2ab341",
       "IPY_MODEL_83eab347f17247b184c4a26f25c36a17",
       "IPY_MODEL_56dc90a26448400e94cd219f8d28d732"
      ],
      "layout": "IPY_MODEL_b9c51bf377ab41489df80de55ec2a0a2"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
