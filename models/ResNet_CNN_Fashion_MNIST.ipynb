{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b2fc36-62fd-40cd-b126-a8192560144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60dce685-f1d1-438b-a102-e45b0ec56dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1  # For BasicBlock, expansion factor is 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269700ea-5a4b-48c7-8135-7d6a202a3bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        # Modified first conv layer: 1 input channel, 64 output channels,\n",
    "        # kernel_size=3, stride=1, padding=1 (instead of 7x7 with stride 2)\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # Do not use maxpool for small images\n",
    "        # self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.maxpool(x)  # Skipped for 28x28 images\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed6cdc5-349b-4701-b91a-ca801baffe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resnet18(num_classes=10):\n",
    "    \"\"\"Constructs a ResNet-18 model.\"\"\"\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c618a03-ccfe-41bc-ac77-256dd491e486",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0acdb7f7-e0e6-4a69-aa2f-10ffe11a5148",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True,\n",
    "                                      transform=transform, download=True)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False,\n",
    "                                     transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b47e2a3f-4bb4-4b40-8c9c-0ac20436203a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/938], Loss: 0.3792\n",
      "Epoch [1/10], Step [200/938], Loss: 0.4059\n",
      "Epoch [1/10], Step [300/938], Loss: 0.3602\n",
      "Epoch [1/10], Step [400/938], Loss: 0.2800\n",
      "Epoch [1/10], Step [500/938], Loss: 0.4655\n",
      "Epoch [1/10], Step [600/938], Loss: 0.4192\n",
      "Epoch [1/10], Step [700/938], Loss: 0.3125\n",
      "Epoch [1/10], Step [800/938], Loss: 0.2447\n",
      "Epoch [1/10], Step [900/938], Loss: 0.5698\n",
      "Epoch [2/10], Step [100/938], Loss: 0.2802\n",
      "Epoch [2/10], Step [200/938], Loss: 0.2631\n",
      "Epoch [2/10], Step [300/938], Loss: 0.3653\n",
      "Epoch [2/10], Step [400/938], Loss: 0.2321\n",
      "Epoch [2/10], Step [500/938], Loss: 0.1611\n",
      "Epoch [2/10], Step [600/938], Loss: 0.2110\n",
      "Epoch [2/10], Step [700/938], Loss: 0.2638\n",
      "Epoch [2/10], Step [800/938], Loss: 0.2235\n",
      "Epoch [2/10], Step [900/938], Loss: 0.3716\n",
      "Epoch [3/10], Step [100/938], Loss: 0.1518\n",
      "Epoch [3/10], Step [200/938], Loss: 0.2050\n",
      "Epoch [3/10], Step [300/938], Loss: 0.1706\n",
      "Epoch [3/10], Step [400/938], Loss: 0.1329\n",
      "Epoch [3/10], Step [500/938], Loss: 0.1674\n",
      "Epoch [3/10], Step [600/938], Loss: 0.1719\n",
      "Epoch [3/10], Step [700/938], Loss: 0.2209\n",
      "Epoch [3/10], Step [800/938], Loss: 0.2069\n",
      "Epoch [3/10], Step [900/938], Loss: 0.1552\n",
      "Epoch [4/10], Step [100/938], Loss: 0.1426\n",
      "Epoch [4/10], Step [200/938], Loss: 0.1188\n",
      "Epoch [4/10], Step [300/938], Loss: 0.1979\n",
      "Epoch [4/10], Step [400/938], Loss: 0.0869\n",
      "Epoch [4/10], Step [500/938], Loss: 0.1261\n",
      "Epoch [4/10], Step [600/938], Loss: 0.1645\n",
      "Epoch [4/10], Step [700/938], Loss: 0.1191\n",
      "Epoch [4/10], Step [800/938], Loss: 0.1375\n",
      "Epoch [4/10], Step [900/938], Loss: 0.2621\n",
      "Epoch [5/10], Step [100/938], Loss: 0.1935\n",
      "Epoch [5/10], Step [200/938], Loss: 0.0919\n",
      "Epoch [5/10], Step [300/938], Loss: 0.1632\n",
      "Epoch [5/10], Step [400/938], Loss: 0.0771\n",
      "Epoch [5/10], Step [500/938], Loss: 0.1956\n",
      "Epoch [5/10], Step [600/938], Loss: 0.1525\n",
      "Epoch [5/10], Step [700/938], Loss: 0.2166\n",
      "Epoch [5/10], Step [800/938], Loss: 0.1282\n",
      "Epoch [5/10], Step [900/938], Loss: 0.1571\n",
      "Epoch [6/10], Step [100/938], Loss: 0.0752\n",
      "Epoch [6/10], Step [200/938], Loss: 0.0881\n",
      "Epoch [6/10], Step [300/938], Loss: 0.0896\n",
      "Epoch [6/10], Step [400/938], Loss: 0.0614\n",
      "Epoch [6/10], Step [500/938], Loss: 0.1104\n",
      "Epoch [6/10], Step [600/938], Loss: 0.0879\n",
      "Epoch [6/10], Step [700/938], Loss: 0.1275\n",
      "Epoch [6/10], Step [800/938], Loss: 0.1298\n",
      "Epoch [6/10], Step [900/938], Loss: 0.1458\n",
      "Epoch [7/10], Step [100/938], Loss: 0.0744\n",
      "Epoch [7/10], Step [200/938], Loss: 0.0424\n",
      "Epoch [7/10], Step [300/938], Loss: 0.0225\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0455\n",
      "Epoch [7/10], Step [500/938], Loss: 0.2217\n",
      "Epoch [7/10], Step [600/938], Loss: 0.1543\n",
      "Epoch [7/10], Step [700/938], Loss: 0.2092\n",
      "Epoch [7/10], Step [800/938], Loss: 0.2703\n",
      "Epoch [7/10], Step [900/938], Loss: 0.0942\n",
      "Epoch [8/10], Step [100/938], Loss: 0.0245\n",
      "Epoch [8/10], Step [200/938], Loss: 0.0688\n",
      "Epoch [8/10], Step [300/938], Loss: 0.0293\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0497\n",
      "Epoch [8/10], Step [500/938], Loss: 0.0642\n",
      "Epoch [8/10], Step [600/938], Loss: 0.1679\n",
      "Epoch [8/10], Step [700/938], Loss: 0.0836\n",
      "Epoch [8/10], Step [800/938], Loss: 0.2010\n",
      "Epoch [8/10], Step [900/938], Loss: 0.0664\n",
      "Epoch [9/10], Step [100/938], Loss: 0.0490\n",
      "Epoch [9/10], Step [200/938], Loss: 0.0174\n",
      "Epoch [9/10], Step [300/938], Loss: 0.0720\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0890\n",
      "Epoch [9/10], Step [500/938], Loss: 0.0413\n",
      "Epoch [9/10], Step [600/938], Loss: 0.0155\n",
      "Epoch [9/10], Step [700/938], Loss: 0.1154\n",
      "Epoch [9/10], Step [800/938], Loss: 0.0731\n",
      "Epoch [9/10], Step [900/938], Loss: 0.0247\n",
      "Epoch [10/10], Step [100/938], Loss: 0.0305\n",
      "Epoch [10/10], Step [200/938], Loss: 0.0924\n",
      "Epoch [10/10], Step [300/938], Loss: 0.0314\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0348\n",
      "Epoch [10/10], Step [500/938], Loss: 0.0169\n",
      "Epoch [10/10], Step [600/938], Loss: 0.1330\n",
      "Epoch [10/10], Step [700/938], Loss: 0.1203\n",
      "Epoch [10/10], Step [800/938], Loss: 0.1019\n",
      "Epoch [10/10], Step [900/938], Loss: 0.0979\n",
      "Training time: 211.96 seconds\n",
      "Accuracy on the test set: 93.13%\n",
      "Inference time: 1.89 seconds for the entire test set\n",
      "Inference time per sample: 0.000189 seconds\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = resnet18(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy on the test set: {100 * correct / total:.2f}%')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    train()\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    test()\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    print(f\"Inference time: {inference_time:.2f} seconds for the entire test set\")\n",
    "    per_sample_inference_time = inference_time / len(test_dataset)\n",
    "    print(f\"Inference time per sample: {per_sample_inference_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cefded55-4c94-45e8-bdce-ee16a6a3a7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 42.70 MB\n"
     ]
    }
   ],
   "source": [
    "    model_path = \"resnet18_fashionmnist_full.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    model_size = os.path.getsize(model_path) / (1024 * 1024)\n",
    "    print(f\"Model size: {model_size:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
