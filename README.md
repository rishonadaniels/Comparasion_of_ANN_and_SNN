# ANN vs. SNN: A Comparative Analysis

This repository contains the code, results, and documentation for the project **"Comparison of Artificial Neural Networks (ANNs) and Spiking Neural Networks (SNNs)."** The goal of this project is to compare ANNs, SNNs, and Vision Transformers (ViT) in terms of architecture, training methods, computational efficiency, and real-world applications.

---

## üìÅ Repository Structure




---

## üöÄ Getting Started

### Prerequisites
- Python >= 3.8
- Required Python libraries:


### Installation
1. Clone the repository:



2. Install dependencies:



---

## üìä Key Features

1. **ANN, CNN, and SNN Implementations**:
- Includes training and evaluation scripts for feedforward ANNs, CNNs, and SNNs.
- SNN implementation supports surrogate gradient learning.

2. **Vision Transformer (ViT) Fine-Tuning**:
- Fine-tuned a pre-trained ViT model on CIFAR-10 for state-of-the-art accuracy.

3. **Comprehensive Performance Metrics**:
- Accuracy, training time, model size, and energy efficiency comparison across architectures.

4. **Detailed Results**:
- Includes visualizations, tables, and logs of experiments conducted on MNIST, Fashion-MNIST, and CIFAR-10.

---

## üß™ How to Run

1. Train models:
- Example (training an ANN on MNIST):
  ```
  python scripts/train_ann.py --dataset mnist --epochs 20
  ```

2. Fine-tune ViT:




3. Visualize results:
- Open the corresponding notebook in `notebooks/`.

---

## üìú Project Documentation
The full project report, including the methodology, results, and conclusion, is available in the `report/` directory.

---

## ü§ù Contributing
Contributions are welcome! If you'd like to improve the repository, feel free to fork it, make changes, and submit a pull request.

---



